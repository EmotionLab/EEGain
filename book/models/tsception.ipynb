{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TSception"
      ],
      "metadata": {
        "id": "egOrUXb3gfE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO\n",
        "\n",
        "\n",
        "1.   Add fit\n",
        "2.   Add predict\n",
        "3.   Add citation\n",
        "\n"
      ],
      "metadata": {
        "id": "X08khLu7trbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "snL0wx3XgiSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TSception from [TSception:A Deep Learning Framework for Emotion Detection Using EEG](https://ieeexplore.ieee.org/abstract/document/9206750/)"
      ],
      "metadata": {
        "id": "unygQ0sGgjZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TSception is a deep learning architecture specifically designed for emotion recognition using electroencephalography (EEG) signals. It combines 1D dilated convolutions and inception modules to capture temporal dependencies and extract discriminative features from the data.\n",
        "\n",
        "The TSception model can be divided into three main parts: the temporal learner, spatial learner, and classifier. Inspired by the Inception block, TSception utilizes multi-scale convolution kernels in the temporal and spatial learners to learn diverse representations of time and space simultaneously.\n",
        "\n",
        "As an end-to-end classification structure, TSception takes raw EEG signals as input. The temporal learner processes the input first, followed by the spatial learner. The learned feature vector is then passed through two fully connected layers to map it to the corresponding emotion label.\n",
        "\n",
        "TSception's architecture enables automatic feature learning from the raw EEG signals, making it a powerful tool for emotion recognition. By incorporating both temporal and spatial information, it captures the complex temporal dependencies and spatial patterns present in the EEG data, leading to improved emotion classification performance."
      ],
      "metadata": {
        "id": "CcpTuEuChjQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> eegain.models.tsception(*num_classes: int = 2, input_size: tuple = (1, 32, 512), sampling_r: int = 128, num_t: int = 15, num_t: int = 15, hidden: int = 32, dropout_rate: int = 0.5*) â†’ TSception [[SOURCE]](https://github.com/RRaphaell/EEGain/blob/main/eegain/models/tsception.py)"
      ],
      "metadata": {
        "id": "B6zBMTGdh7_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "aFaJ8sE6hyXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<figure style=\"width: 100%;\">\n",
        "  \n",
        "| Argument      | Type  | Description                         | Default |\n",
        "|---------------|-------|-------------------------------------|---------|\n",
        "| num_classes   | int   | Number of classes to classify       |   N/A   |\n",
        "| input_size    | int   | 1 x EEG channel x datapoint         |   N/A   |\n",
        "| sampling_r    | int   | Time points in EEG data             |   N/A   |\n",
        "| num_T         | int   | Number of pathways in temporal layers |   N/A   |\n",
        "| num_S         | int   | Number of pathways in spatial layers  |   N/A   |\n",
        "| hidden        | int   | Number of hidden units               |   N/A   |\n",
        "| dropout_rate  | float | Dropout fraction                     |   N/A   |\n",
        "\n",
        "</figure>\n"
      ],
      "metadata": {
        "id": "sEdBanBIpm3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example from Framework"
      ],
      "metadata": {
        "id": "7BHHPseOleIK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewdFEPpifqm3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install eegain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from eegain.models import TSception\n",
        "\n",
        "model = TSception(\n",
        "    num_classes=2,\n",
        "    input_size=(1, 32, 512),\n",
        "    sampling_r=128,\n",
        "    num_t=15,\n",
        "    num_s=15,\n",
        "    hidden=32,\n",
        "    dropout_rate=0.5,\n",
        ")"
      ],
      "metadata": {
        "id": "tT2zCkBClh_n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
